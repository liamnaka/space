{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiments.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMkRXJFRskqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "from os.path import join\n",
        "\n",
        "# Create a folder in your drive 'cs236/project' to host in progress code/logs\n",
        "ROOT = '/content/drive'\n",
        "PROJ = 'My Drive/cs236/project'  \n",
        "drive.mount(ROOT)\n",
        "PROJECT_PATH = join(ROOT, PROJ)\n",
        "!mkdir \"{PROJECT_PATH}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNm7zdA8ufl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GIT_USER = \"liamnaka\"\n",
        "GIT_REPO = \"space\"\n",
        "GIT_PATH = \"https://github.com/{}/{}.git\".format(GIT_USER, GIT_REPO)\n",
        "GIT_BRANCH = \"master\"\n",
        "\n",
        "%cd \"{PROJECT_PATH}\" \n",
        "!git clone \"{GIT_PATH}\"\n",
        "%cd \"{PROJECT_PATH}\"/\"{GIT_REPO}\"\n",
        "!git checkout \"{GIT_BRANCH}\" \n",
        "!git pull\n",
        "%cd /content\n",
        "!rsync -aP --exclude=data/ \"{PROJECT_PATH}\"/*  ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLnpzj_IqZPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First, add the official CelebA drive folder from \n",
        "# (http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) to your own drive within\n",
        "# 'cs236/project/data/'\n",
        "# Unzip CelebA - this should take about a minute\n",
        "\n",
        "import zipfile\n",
        "IMG_PATH = 'data/CelebA/Img/img_align_celeba.zip'\n",
        "with zipfile.ZipFile(join(PROJECT_PATH, IMG_PATH),\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"data/CelebA\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnbk1QmAxVUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/space\n",
        "!git submodule sync\n",
        "!git submodule update --init --remote --recursive\n",
        "%cd /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oBZKUCk1xUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "module_path = os.path.abspath(os.path.join('/content/space/'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "module_path = os.path.abspath(os.path.join('/content/space/HoloGAN'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKtxQMIF598b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.argv[1] = '/content/space/config_ViewHoloGAN.json'\n",
        "\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from space.model import ViewHoloGAN\n",
        "from space.HoloGAN.tools.utils import pp, show_all_variables\n",
        "\n",
        "with open(sys.argv[1], 'r') as fh:\n",
        "    cfg = json.load(fh)\n",
        "OUTPUT_DIR = cfg['output_dir']\n",
        "LOGDIR = os.path.join(OUTPUT_DIR, \"log\")\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{0}\".format(cfg['gpu'])\n",
        "\n",
        "flags = tf.app.flags\n",
        "flags.DEFINE_integer(\"input_height\", 108, \"The size of image to use (will be center cropped). [108] or [128] for celebA and lsun, [400] for chairs. Cats and Cars are already cropped\")\n",
        "flags.DEFINE_integer(\"input_width\", None, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
        "flags.DEFINE_integer(\"output_height\", 64, \"The size of the output images to produce 64 or 128\")\n",
        "flags.DEFINE_integer(\"output_width\", None, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
        "flags.DEFINE_string(\"dataset\", \"celebA\", \"The name of dataset [celebA, lsun, chairs, shoes, cars, cats]\")\n",
        "flags.DEFINE_string(\"input_fname_pattern\", \"*.jpg\", \"Glob pattern of filename of input images [*]\")\n",
        "flags.DEFINE_float(\"train_size\", np.inf, \"Number of images to train-Useful when only a subset of the dataset is needed to train the model\")\n",
        "flags.DEFINE_boolean(\"crop\", True, \"True for training, False for testing [False]\")\n",
        "flags.DEFINE_boolean(\"train\", True, \"True for training, False for testing [False]\")\n",
        "flags.DEFINE_boolean(\"rotate_azimuth\", False, \"Sample images with varying azimuth\")\n",
        "flags.DEFINE_boolean(\"rotate_elevation\", False, \"Sample images with varying elevation\")\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44JrSjJC3r1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pp.pprint(flags.FLAGS.__flags)\n",
        "if FLAGS.input_width is None:\n",
        "    FLAGS.input_width = FLAGS.input_height\n",
        "if FLAGS.output_width is None:\n",
        "    FLAGS.output_width = FLAGS.output_height\n",
        "if not os.path.exists(LOGDIR):\n",
        "    os.makedirs(LOGDIR)\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "run_config = tf.ConfigProto()\n",
        "run_config.gpu_options.allow_growth=True\n",
        "print(\"FLAGs \" + str(FLAGS.dataset))\n",
        "with tf.Session(config=run_config) as sess:\n",
        "    model = ViewHoloGAN(\n",
        "        cfg,\n",
        "        sess,\n",
        "        input_width=FLAGS.input_width,\n",
        "        input_height=FLAGS.input_height,\n",
        "        output_width=FLAGS.output_width,\n",
        "        output_height=FLAGS.output_height,\n",
        "        dataset_name=FLAGS.dataset,\n",
        "        input_fname_pattern=FLAGS.input_fname_pattern,\n",
        "        crop=FLAGS.crop)\n",
        "\n",
        "    model.build(cfg['build_func'])\n",
        "\n",
        "    show_all_variables()\n",
        "\n",
        "    if FLAGS.train:\n",
        "        train_func = eval(\"model.\" + (cfg['train_func']))\n",
        "        train_func(FLAGS)\n",
        "    else:\n",
        "        if not model.load(LOGDIR)[0]:\n",
        "            raise Exception(\"[!] Train a model first, then run test mode\")\n",
        "        sample_func = eval(\"model.\" + (cfg['sample_func']))\n",
        "        sample_func(FLAGS)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}